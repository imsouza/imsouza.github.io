---
layout: note
title: "Resumo SO 2"
author: "Mateus Almeida"
categories: [notas]
tags: [Sistemas Operacionais]
---

## Slide 11

>O que é o problema da seção crítica em sistemas operacionais?

O problema da seção crítica está relacionado com os processos tentando acessar a região crítica simultaneamente - o que não deve acontecer, pois, gera inconsistências no sistema.

>Qual é a característica importante do sistema relacionada à seção crítica?

A característica importante do SO relacionado à seção crítica é garantir a exclusão mútua, ou seja, os processos podem acessar a região crítica um de cada vez. A garantia de exclusão mútua é alcançada por meio de mecanismos de sincronização como semáforos e mutexes.

>Quais são os três requisitos que uma solução para o problema da seção crítica deve satisfazer? Explique cada um deles:

- 1) Exclusão Mútua: se um processo está executando sua seção crítica, então nenhum outro processo pode executar ela ao mesmo tempo.
- 2) Progresso: Se nenhum processo está na região crítica, então apenas os processos que não estão executando suas ações, ou seja, que estão ociosos, e que não estão na região crítica podem requisitá-la.
- 3) Espera Limitada: há um limite de quantas vezes cada processo pode solicitar acesso a região crítica após um outro processo ter solicitado para entrar. Resumidamente é a quantidade de vezes que um processo pode "furar a fila" para acessar a região crítica primeiro do que outro processo que solicitou anteriormente.
     
>O que é uma condição de corrida e como ela se relaciona com o problema da seção crítica? Dê exemplos de estruturas do kernel sujeitas a condições de corrida.

Uma condição de corrida ocorre quando múltiplos processos ou threads tentam acessar a região crítica simultaneamente. As estruturas sujeitas a condições de corrida são: alocação de memória, lista de processos, manipulação de interrupções.

>Quais são as duas abordagens gerais usadas para lidar com seções críticas em sistemas operacionais?

- 1) Kernel com preempção: permite que um processo seja interceptado por outro evento enquanto está sendo executado na modalidade de kernel.
- 2) Kernel sem preempção: não permite que um processo seja interceptado.

>Por que os kernels com preempção são difíceis de projetar para arquiteturas SMP?

São difíceis de projetar pois é possível que dois processos em modalidade de kernel sejam executados simultaneamente em diferentes processadores.

>Apesar das dificuldades de projeto, por que alguém poderia preferir um kernel com preempção?

O kernel com preempção apresenta melhor capacidade de resposta, pois, há menos risco de um processo em modalidade kernel ser executado por um período de tempo arbitrariamente longo.

>Quais são os três pontos que precisam ser demonstrados para mostrar que a Solução de Peterson está correta?

- 1) Exclusão mútua é preservada.
- 2) Requisito do progresso é atendido.
- 3) Requisito da espera limitada é atendido.

>O que significa trancamento (locking) e como é utilizado para proteger regiões críticas?

Locking refere-se à técnica de usar mecanismos de bloqueio (semáforos, mutex, monitores) para proteger acesso a recursos compartilhados, como variáveis ou seções críticas.

## Slide 12

>Por que as soluções baseadas em hardware para o problema da seção crítica são consideradas complicadas para programadores de aplicação?

É complicada pois requer soluções a nível da hardware e pode ser complexo pois não existe abstrações de software nesta camada,

>O que é um semáforo e qual é a sua característica principal?

Um semáforo é uma solução para o problema de sincronização de processos, do qual contém uma variável inteira que é acessada por duas operações padrão: acquire e release. As modificações feitas por essas operações devem ser indivisível, ou seja, quando uma thread modificar o valor do semáforo, nenhuma outra thread poderá modificar simultaneamente.

>Quais são as duas operações padrão realizadas em um semáforo?

Um semáforo tem duas operações padrões para o sincronismo de processos, em java: acquire() para solicitar entrada na seção crítica (decrementa o contador) e release() para liberar acesso à seção crítica (incrementa o contador).

>Por que as modificações no valor inteiro do semáforo nas operações acquire() e release() precisam ser executadas de modo indivisível?

Pois, quando uma thread modificar o valor do semáforo, nenhuma outra thread poderá modificar esse valor simultaneamente.

>Quais são as diferenças entre semáforos contadores e semáforos binários?

- Semáforo Contador: o valor de um semáforo contador pode variar em um range específico. Têm como propósito controlar o acesso a um número específico de recursos, um semáforo contador pode estar relacionado a mais de uma thread. Pode conter o problema do spinlock.

- Semáforo Binário: o valor de um semáforo binário só pode ser 0 ou 1. Têm como propósito ser usado em situações de exclusão mútua, o semáforo binário está relacionado com pelo menos 2 threads para comparação.

## Slide 14

>Qual é a principal desvantagem dos semáforos?

Nos semáforos contadores a principal desvantagem é o uso da espera ocupada, ou seja, qualquer outro processo que quiser entrar na região crítica ficará em um looping contínuo até a região crítica desocupar. Esse looping contínuo é chamado de busy waiting e é um problema pois desperdiça ciclos de CPU que um outro processo poderia usar de forma produtiva, um semáforo com busy waiting é chamado de spinlock.

>Como podemos modificar as operações acquire() e release() para evitar a espera ocupada?

Quando um processo executa uma operação acquire e descobre que o valor do semáforo não é positivo, ele precisa esperar. Porém, ao invés de usar busy waiting o processo pode se auto-bloquear, ou seja, é chamada a operação lock que coloca o processo em uma fila de espera associada ao semáforo e o estado do processo é passado para o estado de esperando. Em seguida, o controle fica a critério do escalonador de CPU para selecionar outro processo para ser executado.

>Como um processo bloqueado pode ser reiniciado na implementação que utiliza bloqueio?

O processo deve ser reiniciado quando algum outro processo executa a operação release, assim, liberando a região crítica, o processo é reiniciado pela chamada da operação wakeup que muda o processo do estado de esperando para o de pronto. 

>Por que é crucial garantir que as operações acquire() e release() não sejam executadas simultaneamente por dois processos?

Pois essa situação cria um problema de seção crítica.

>Quais são as duas maneiras mencionadas para resolver esse problema em sistemas uniprocessados e multiprocessados?

- 1) Desabilitar as interrupções quando acquire e release não estão sendo executadas.
- 2) Outra solução é o hardware fornecer suporte com instruções atômicas para testar e modificar uma palavra de memória.

## Slide 15

>Como você definiria deadlock (impasse) em um sistema operacional?

Quando dois ou mais processos aguardam indefinidamente por um recurso que está sendo retido por outro processo, assim, todos processos se encontram no estado de bloqueado.

>Qual situação leva ao deadlock em sistemas que utilizam semáforos com fila de espera?

Em sistemas que utilizam semáforos com fila de espera, um evento que pode levar a situações de deadlock é a espera circular.

>Quais são os principais eventos que podem causar deadlocks?

Aquisição e liberação de recursos.

>O que é o problema de starvation (inanição) em sistemas operacionais?

Quando um ou mais processos esperam indefinidamente dentro do semáforo por um recurso R contido na região crítica que está de posse de um outro processo de prioridade maior.

>Quais são as decisões de escalonamento da CPU:

- 1) Quando o processo passa do estado de execução para espera
- 2) Quando o processo passa do estado de execução para pronto
- 3) Quando o processo passa do estado de espera para pronto
- 4) Quando o processo termina

>Quais são as situações em que ocorre o scheduling sem preempção?

Somente quando um processo passa do estado de execução para espera e quando o processo termina.

>Qual é o papel do despachante no contexto do escalonamento da CPU?

É o módulo responsável por executar o processo selecionado pelo escalonador de curto prazo.

>Por que o scheduling cooperativo pode resultar em condições de corrida quando dados são compartilhados entre processos?

Pois, processos cooperativos possuem compartilhamento de recursos, logo é possivel condições de corrida.

>Quais são os critérios comuns usados para comparar algoritmos de escalonamento da CPU?

- 1) Utilização da CPU
- 2) Vazão
- 3) Turnaround
- 4) Tempo de Espera
- 5) Tempo de Resposta

## Extra